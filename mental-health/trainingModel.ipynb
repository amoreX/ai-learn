{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064d4362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"distilbert/distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=5, # number of  possible outcomes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7f8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data_files={\n",
    "    \"train\":\"dataset/train.jsonl\",\n",
    "    \"validation\":\"dataset/val.jsonl\",\n",
    "    \"test\":\"dataset/test.jsonl\"\n",
    "}\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226ca85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = dataset[\"test\"].filter(\n",
    "    lambda example: isinstance(example[\"text\"], str) and example[\"text\"].strip() != \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590aab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"Normal\": 0,\n",
    "    \"Bipolar\": 1,\n",
    "    \"Anxiety\": 2,\n",
    "    \"Suicidal\": 3,\n",
    "    \"Depression\": 4\n",
    "}\n",
    "\n",
    "def encode_labels(example):\n",
    "    if example.get(\"class\") in label_map:\n",
    "        example[\"label\"] = label_map[example[\"class\"]]\n",
    "    else:\n",
    "        example[\"label\"] = -1  # Optional: handle unknown labels\n",
    "    return example\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[split] = dataset[split].map(encode_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392d2bd",
   "metadata": {},
   "source": [
    "# Get rid of invalid labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e0d4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_invalid(example):\n",
    "    return example[\"label\"] != -1\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[split] = dataset[split].filter(filter_invalid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497f7b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'class', 'label'],\n",
      "        num_rows: 15935\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'text', 'class', 'label'],\n",
      "        num_rows: 1997\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'text', 'class', 'label'],\n",
      "        num_rows: 1994\n",
      "    })\n",
      "})\n",
      "{'id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'class': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset[\"test\"].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83998be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_empty(example):\n",
    "    text = example.get(\"text\", \"\")  # Safely get \"text\", defaulting to empty string if it's missing or None\n",
    "    return isinstance(text, str) and text.strip() != \"\"\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[split] = dataset[split].filter(is_not_empty)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8c7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Initialize a list to store tokenized results\n",
    "    tokenized_results = []\n",
    "    \n",
    "    for text in examples['text']:\n",
    "        try:\n",
    "            \n",
    "            tokenized_results.append(tokenizer(text, padding='max_length', truncation=True,max_length=32))\n",
    "        except Exception as e:\n",
    "            # Print the problematic text and continue with the next one\n",
    "            print(f\"Error tokenizing: {text} - Error: {e}\")\n",
    "            tokenized_results.append(None)  # Append None for problematic cases\n",
    "\n",
    "    # Return the tokenized results\n",
    "    return {\"input_ids\": [result['input_ids'] if result is not None else [] for result in tokenized_results],\n",
    "            \"attention_mask\": [result['attention_mask'] if result is not None else [] for result in tokenized_results]}\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Filter out any examples that were returned as empty dictionaries \n",
    "tokenized_datasets = tokenized_datasets.filter(lambda example: example != {})\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.rename_columns({\"label\": \"labels\"})  # Ensure the label column is named \"labels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "326c0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory for model checkpoints\n",
    "    # evaluation_strategy=\"epoch\",     # evaluation strategy to use\n",
    "    learning_rate=1e-5,              # learning rate\n",
    "    per_device_train_batch_size=4,   # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "    num_train_epochs=1,              # number of training epochs\n",
    "    weight_decay=0.1,               # strength of weight decay\n",
    "    save_strategy =\"no\",\n",
    "    logging_dir=\"./logs\",            \n",
    "    \n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                          \n",
    "    args=training_args,                  \n",
    "    train_dataset=tokenized_datasets[\"train\"],  \n",
    "    eval_dataset=tokenized_datasets[\"validation\"],  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df18390f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3982' max='3982' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3982/3982 03:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.885700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.653400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.574100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.541500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.515500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.494700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3982, training_loss=0.589631107930021, metrics={'train_runtime': 196.2545, 'train_samples_per_second': 81.16, 'train_steps_per_second': 20.29, 'total_flos': 131878350574080.0, 'train_loss': 0.589631107930021, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d50d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5229761600494385,\n",
       " 'eval_runtime': 2.2342,\n",
       " 'eval_samples_per_second': 893.397,\n",
       " 'eval_steps_per_second': 111.898,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b89dda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5061888694763184,\n",
       " 'eval_runtime': 2.2004,\n",
       " 'eval_samples_per_second': 906.188,\n",
       " 'eval_steps_per_second': 113.614,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49b724c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mental_health_bud/tokenizer_config.json',\n",
       " 'mental_health_bud/special_tokens_map.json',\n",
       " 'mental_health_bud/vocab.txt',\n",
       " 'mental_health_bud/added_tokens.json',\n",
       " 'mental_health_bud/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"mental_health_bud\")\n",
    "tokenizer.save_pretrained(\"mental_health_bud\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55d6fd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dont know how am feeling , it could be bad tho\n",
      "{'label': 'normal', 'label_index': 0, 'score': 0.5374}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Updated label map\n",
    "label_map = {\n",
    "    0: \"normal\",\n",
    "    1: \"bipolar\",\n",
    "    2: \"anxiety\",\n",
    "    3: \"suicidal\",\n",
    "    4: \"depression\"\n",
    "}\n",
    "\n",
    "# Load the model pipeline\n",
    "pipe_budy = pipeline(\"text-classification\", model=\"mental_health_bud\", tokenizer=tokenizer)\n",
    "\n",
    "# Function to interpret output\n",
    "def interpret_output(output):\n",
    "    label_str = output[0]['label']  # e.g., \"LABEL_4\"\n",
    "    label_index = int(label_str.replace(\"LABEL_\", \"\"))  # safely extract the index\n",
    "    readable_label = label_map.get(label_index, \"Unknown\")\n",
    "    return {\n",
    "        \"label\": readable_label,\n",
    "        \"label_index\": label_index,\n",
    "        \"score\": round(output[0]['score'], 4)  # optional rounding\n",
    "    }\n",
    "# Take input\n",
    "prompt = input(\"How are you feeling: \")\n",
    "print(prompt)\n",
    "\n",
    "# Predict\n",
    "prediction = pipe_budy(prompt)\n",
    "\n",
    "# Interpret\n",
    "interpreted_prediction = interpret_output(prediction)\n",
    "\n",
    "# Show result\n",
    "print(interpreted_prediction)\n",
    "# print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
